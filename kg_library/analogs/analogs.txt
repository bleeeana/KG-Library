1. Rebel model: https://github.com/Babelscape/rebel.git
Особенности:
    Использует BART (Bidirectional and Auto-Regressive Transformers) в архитектуре seq2seq для извлечения отношений из текста.
    Вместо классического классификационного подхода к извлечению отношений представляет извлеченные триплеты в текстовом формате, что упрощает процесс.
    Обучен на Wikidata, что позволяет охватывать более 200 типов отношений.

Предобработка:
    Текст токенизируется с помощью BART Tokenizer.
    Используется chunking для разбиения текста на части подходящего размера.
    Пронумерованные сущности передаются модели в последовательности, чтобы она могла интерпретировать их в виде триплетов.

Плюсы:
    Гибкость: Работает без необходимости ручной аннотации данных, используя seq2seq для предсказания отношений.
    Поддерживает множество типов отношений (более 200), что делает его универсальным решением.
    Можно дообучать под конкретные домены.
    Подходит для разных языков (особенно с дообучением).

Минусы:
    Может генерировать ложные связи из-за текстовой генерации, особенно на неструктурированных текстах.
    Ограниченный контроль над предсказанными триплетами, так как генерация основана на seq2seq.
    Не генерирует эмбеддинги для последующего использования в link prediction.

2. IBM Grapher: https://github.com/IBM/Grapher.git
    Особенности:
    Основан на графовых нейронных сетях (GNN), что делает его ближе к классическому knowledge graph embedding подходу.
    Использует BERT-like модели для извлечения сущностей и отношений, но затем строит граф на их основе.
    Поддерживает link prediction, то есть может дополнять граф новыми связями и сущностями.

Предобработка:
    Использует стандартную токенизацию BERT.
    NER (Named Entity Recognition) для выделения сущностей.
    Dependency Parsing для структурирования отношений.
    Graph Neural Networks для обучения представлений узлов и рёбер.

Плюсы:
    Комбинирует преимущества трансформеров и графовых нейросетей.
    Поддерживает link prediction, что позволяет дополнять существующий граф.
    Лучше интерпретирует сложные отношения, чем seq2seq-подходы.

Минусы:
    Высокие требования к ресурсам ввиду использования GNN

3. Relik: https://github.com/SapienzaNLP/relik.git
Особенности:
    Использует T5 для извлечения связей между сущностями.
    Работает не только с извлечением отношений, но и с их сопоставлением (linking) с существующим знанием в графах.
    Не создаёт эмбеддинги для дальнейшего link prediction, в отличие от IBM Grapher.

Предобработка:
    Токенизация через T5 Tokenizer.
    NER-аннотирование с выделением сущностей перед передачей в модель.
    Фильтрация некорректных связей путём постобработки предсказаний.

Плюсы:
    Хорошо работает с существующими графами знаний, так как включает linking.
    Использует мощь T5, который подходит для генерации текстовых отношений.
    Может работать с разными источниками данных (викиданные, DBpedia).

Минусы:
    Не подходит для чистой генерации графа с нуля, в отличие от IBM Grapher.
    Отсутствует генерация эмбеддингов, что делает невозможным link prediction.